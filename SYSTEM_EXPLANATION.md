# LLM Observe - Granular System Explanation

## ğŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER'S APPLICATION                              â”‚
â”‚  (Python script, FastAPI app, Django app, etc.)                        â”‚
â”‚                                                                         â”‚
â”‚  1. User imports: import llmobserve                                     â”‚
â”‚  2. User calls: llmobserve.observe(collector_url, api_key)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SDK INITIALIZATION (observe.py)                      â”‚
â”‚                                                                         â”‚
â”‚  Step 1: Configuration                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ config.configure(                                               â”‚  â”‚
â”‚  â”‚     collector_url="http://localhost:8000",                       â”‚  â”‚
â”‚  â”‚     api_key="llmo_sk_...",                                      â”‚  â”‚
â”‚  â”‚     flush_interval_ms=500,                                       â”‚  â”‚
â”‚  â”‚     customer_id=None                                            â”‚  â”‚
â”‚  â”‚ )                                                                â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ Stores in global _config dict:                                  â”‚  â”‚
â”‚  â”‚   - collector_url: Where to send events                          â”‚  â”‚
â”‚  â”‚   - api_key: Authentication token                               â”‚  â”‚
â”‚  â”‚   - flush_interval_ms: How often to batch send (500ms)          â”‚  â”‚
â”‚  â”‚   - enabled: True (unless LLMOBSERVE_DISABLED=1)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚  Step 2: Instrumentation                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ auto_instrument(libs=None)  # Instruments all registered libs   â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ This calls:                                                      â”‚  â”‚
â”‚  â”‚   - instrument_openai()                                          â”‚  â”‚
â”‚  â”‚   - instrument_pinecone()                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚  Step 3: Start Background Flush Timer                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ buffer.start_flush_timer()                                      â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ Creates threading.Timer that calls flush_events() every 500ms    â”‚  â”‚
â”‚  â”‚ Runs in background daemon thread (doesn't block app)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INSTRUMENTATION LAYER (instrumentation/)                    â”‚
â”‚                                                                         â”‚
â”‚  How OpenAI Instrumentation Works:                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ instrument_openai()                                             â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 1. Version Check:                                               â”‚  â”‚
â”‚  â”‚    - Checks OpenAI SDK version                                  â”‚  â”‚
â”‚  â”‚    - Warns if unsupported                                       â”‚  â”‚
â”‚  â”‚    - Returns False if incompatible (fail-open)                  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 2. Import OpenAI:                                               â”‚  â”‚
â”‚  â”‚    - import openai                                              â”‚  â”‚
â”‚  â”‚    - from openai import resources                               â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 3. Check if Already Instrumented:                               â”‚  â”‚
â”‚  â”‚    - if hasattr(resources.chat.Completions, "_llmobserve_...")  â”‚  â”‚
â”‚  â”‚    - Prevents double-patching                                    â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 4. Patch Each Endpoint:                                         â”‚  â”‚
â”‚  â”‚    For each endpoint (chat.completions, embeddings, etc.):      â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚    a. Get original method:                                      â”‚  â”‚
â”‚  â”‚       original = getattr(resources.chat.Completions, "create")  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚    b. Create wrapper:                                           â”‚  â”‚
â”‚  â”‚       wrapped = _create_safe_wrapper(...)                       â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚    c. Replace method:                                           â”‚  â”‚
â”‚  â”‚       setattr(resources.chat.Completions, "create", wrapped)    â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚    d. Mark as instrumented:                                     â”‚  â”‚
â”‚  â”‚       wrapped._llmobserve_instrumented = True                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RUNTIME: USER CALLS OPENAI                                  â”‚
â”‚                                                                         â”‚
â”‚  User Code:                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ from openai import OpenAI                                       â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ client = OpenAI()                                               â”‚  â”‚
â”‚  â”‚ response = client.chat.completions.create(                      â”‚  â”‚
â”‚  â”‚     model="gpt-4o",                                             â”‚  â”‚
â”‚  â”‚     messages=[{"role": "user", "content": "Hello!"}]            â”‚  â”‚
â”‚  â”‚ )                                                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚  What Actually Happens:                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. client.chat.completions.create() is called                   â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 2. But it's been replaced with our wrapper!                     â”‚  â”‚
â”‚  â”‚    â†’ Goes to sync_wrapper() instead of original method          â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 3. sync_wrapper() executes:                                     â”‚  â”‚
â”‚  â”‚    a. Extract model from kwargs: model = kwargs.get("model")    â”‚  â”‚
â”‚  â”‚    b. Check if streaming: is_streaming = kwargs.get("stream")   â”‚  â”‚
â”‚  â”‚    c. Record start time: start_time = time.time()               â”‚  â”‚
â”‚  â”‚    d. Build endpoint name: "chat.completions.create"           â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 4. Call original method (critical path - never fails here):     â”‚  â”‚
â”‚  â”‚    try:                                                          â”‚  â”‚
â”‚  â”‚        response = original_method(*args, **kwargs)              â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 5. Handle response:                                              â”‚  â”‚
â”‚  â”‚    if is_streaming:                                             â”‚  â”‚
â”‚  â”‚        return _wrap_streaming_response(...)                     â”‚  â”‚
â”‚  â”‚    else:                                                         â”‚  â”‚
â”‚  â”‚        track_openai_call(...)  # Track immediately              â”‚  â”‚
â”‚  â”‚        return response                                          â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 6. If error occurs:                                             â”‚  â”‚
â”‚  â”‚    except Exception as e:                                       â”‚  â”‚
â”‚  â”‚        track_openai_call(..., error=e)  # Track error          â”‚  â”‚
â”‚  â”‚        raise  # Re-raise original exception                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EVENT TRACKING (track_openai_call)                         â”‚
â”‚                                                                         â”‚
â”‚  Step-by-Step Event Creation:                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Extract Usage from Response:                                â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ input_tokens = response.usage.prompt_tokens             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ output_tokens = response.usage.completion_tokens        â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ cached_tokens = response.usage.prompt_tokens_details    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                          .cached_tokens                  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 2. Calculate Cost:                                              â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ cost = pricing.compute_cost(                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     provider="openai",                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     model="gpt-4o",                                       â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     input_tokens=100,                                     â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     output_tokens=50,                                      â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     cached_tokens=20  # 10% discount                        â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ )                                                          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ Looks up in PRICING_REGISTRY:                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   "openai:gpt-4o": {                                      â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "input": 0.000005,  # per 1K tokens                   â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "output": 0.000015                                     â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   }                                                        â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ Calculates:                                                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   input_cost = (100 / 1000) * 0.000005 = $0.0000005       â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   output_cost = (50 / 1000) * 0.000015 = $0.00000075      â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   cached_cost = (20 / 1000) * 0.000005 * 0.1 = $0.00000001â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   total = $0.00000124                                      â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 3. Get Context Information:                                      â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ run_id = context.get_run_id()                           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Returns current ContextVar value                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ If None, auto-generates UUID4                       â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ section_path = context.get_section_path()              â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Returns full path like:                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   "agent:researcher/tool:web_search/step:analyze"       â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Built from section_stack ContextVar                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ span_id = context.get_current_span_id()                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ UUID4 from current section in stack                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ parent_span_id = context.get_parent_span_id()           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ UUID4 from parent section in stack                  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ customer_id = context.get_customer_id()                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Current customer ContextVar value                   â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 4. Calculate Latency:                                           â”‚  â”‚
â”‚  â”‚    latency_ms = (time.time() - start_time) * 1000               â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 5. Create Event Dictionary:                                     â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ event = {                                                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "id": str(uuid.uuid4()),                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "run_id": "abc-123-def",                              â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "span_id": "span-456",                                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "parent_span_id": "span-789",                         â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "section": "step:analyze",  # Last segment            â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "section_path": "agent:researcher/tool:web_search/...",â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "span_type": "llm",                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "provider": "openai",                                  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "endpoint": "chat.completions.create",                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "model": "gpt-4o",                                     â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "customer_id": "customer_123",                          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "input_tokens": 100,                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "output_tokens": 50,                                     â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "cached_tokens": 20,                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "cost_usd": 0.00000124,                                  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "latency_ms": 1250.5,                                   â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "status": "ok",                                         â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "is_streaming": False,                                  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "stream_cancelled": False,                              â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "event_metadata": {},                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     "schema_version": "1.0"                                  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ }                                                           â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 6. Enrich with Retry Metadata:                                  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ event = enrich_event_with_retry_metadata(event)         â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ Checks if this is a retry by:                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - Looking at section_path for retry patterns           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - Checking operation_id in metadata                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ Adds:                                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - attempt_number: 1, 2, 3...                            â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - is_retry: True/False                                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - operation_id: UUID for grouping retries              â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 7. Add to Buffer:                                                â”‚  â”‚
â”‚  â”‚    buffer.add_event(event)                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EVENT BUFFERING (buffer.py)                                 â”‚
â”‚                                                                         â”‚
â”‚  Thread-Safe Bounded Queue:                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ _event_queue = queue.Queue(maxsize=10000)                      â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ add_event(event):                                               â”‚  â”‚
â”‚  â”‚   1. Check if enabled: if not config.is_enabled(): return      â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚   2. Try to add (non-blocking):                                 â”‚  â”‚
â”‚  â”‚      try:                                                        â”‚  â”‚
â”‚  â”‚          _event_queue.put_nowait(event)                         â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚   3. If queue full (queue.Full exception):                      â”‚  â”‚
â”‚  â”‚      a. Remove oldest: _event_queue.get_nowait()                â”‚  â”‚
â”‚  â”‚      b. Add new one: _event_queue.put_nowait(event)             â”‚  â”‚
â”‚  â”‚      c. Increment dropped_count                                 â”‚  â”‚
â”‚  â”‚      d. Log warning every 100 drops                              â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ Why bounded queue?                                               â”‚  â”‚
â”‚  â”‚   - Prevents memory bloat if collector is down                 â”‚  â”‚
â”‚  â”‚   - Drop-oldest policy: lose old data, keep new                â”‚  â”‚
â”‚  â”‚   - Thread-safe: multiple threads can add simultaneously        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚  Background Flush Timer:                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ start_flush_timer():                                            â”‚  â”‚
â”‚  â”‚   1. Creates threading.Timer (daemon thread)                    â”‚  â”‚
â”‚  â”‚   2. Timer calls _flush_and_reschedule() after 500ms           â”‚  â”‚
â”‚  â”‚   3. _flush_and_reschedule():                                   â”‚  â”‚
â”‚  â”‚      a. Calls flush_events()                                    â”‚  â”‚
â”‚  â”‚      b. Reschedules itself (recursive timer)                    â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ Why daemon thread?                                             â”‚  â”‚
â”‚  â”‚   - Doesn't prevent app shutdown                                â”‚  â”‚
â”‚  â”‚   - Automatically killed when main thread exits                 â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ Cleanup on Exit:                                                 â”‚  â”‚
â”‚  â”‚   - atexit.register(_cleanup)                                    â”‚  â”‚
â”‚  â”‚   - Flushes remaining events on app shutdown                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EVENT TRANSPORT (transport.py)                             â”‚
â”‚                                                                         â”‚
â”‚  Flush Process (Every 500ms):                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ flush_events():                                                  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 1. Get events from buffer:                                      â”‚  â”‚
â”‚  â”‚    events = get_and_clear_buffer()                              â”‚  â”‚
â”‚  â”‚    â†’ Drains queue (non-blocking)                                â”‚  â”‚
â”‚  â”‚    â†’ Returns list of all buffered events                         â”‚  â”‚
â”‚  â”‚    â†’ Clears queue                                                â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 2. If no events: return early                                    â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 3. Exponential Backoff Retry (max 3 attempts):                  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ for attempt in range(3):                                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   try:                                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚       # Try to send HTTP POST                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚       response = requests.post(                           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           url=f"{collector_url}/events",                   â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           json=events,  # Batch of events                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           headers={                                       â”‚  â”‚  â”‚
â”‚  â”‚    â”‚               "Authorization": f"Bearer {api_key}",        â”‚  â”‚  â”‚
â”‚  â”‚    â”‚               "Content-Type": "application/json"          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           },                                               â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           timeout=5                                        â”‚  â”‚  â”‚
â”‚  â”‚    â”‚       )                                                    â”‚  â”‚  â”‚
â”‚  â”‚    â”‚       response.raise_for_status()                          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚       return  # Success!                                   â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   except Exception as e:                                   â”‚  â”‚  â”‚
â”‚  â”‚    â”‚       if attempt < 2:  # Not last attempt                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           delay = 1.0 * (2 ** attempt)  # 1s, 2s, 4s     â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           time.sleep(delay)                                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           continue  # Retry                               â”‚  â”‚  â”‚
â”‚  â”‚    â”‚       else:                                                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           logger.debug(f"Failed after 3 attempts: {e}")   â”‚  â”‚  â”‚
â”‚  â”‚    â”‚           return  # Fail-open: don't break app            â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ Why exponential backoff?                                        â”‚  â”‚
â”‚  â”‚   - Reduces load on collector if it's slow                      â”‚  â”‚
â”‚  â”‚   - Gives collector time to recover                             â”‚  â”‚
â”‚  â”‚   - Prevents thundering herd                                    â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ Why fail-open?                                                   â”‚  â”‚
â”‚  â”‚   - Never breaks user's application                              â”‚  â”‚
â”‚  â”‚   - Events are lost, but app continues                          â”‚  â”‚
â”‚  â”‚   - Better than crashing user's code                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚  Signal Handling:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ signal.signal(signal.SIGTERM, _handle_signal)                 â”‚  â”‚
â”‚  â”‚ signal.signal(signal.SIGINT, _handle_signal)                  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ _handle_signal():                                               â”‚  â”‚
â”‚  â”‚   - Flushes remaining events before shutdown                    â”‚  â”‚
â”‚  â”‚   - Ensures no data loss on graceful shutdown                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ HTTP POST /events (batch)
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COLLECTOR API (FastAPI)                                    â”‚
â”‚                                                                         â”‚
â”‚  Event Ingestion Endpoint:                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ POST /events                                                    â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 1. Authentication:                                               â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ get_current_user_id()                                   â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - Extracts API key from Authorization header          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - Looks up key_hash in api_keys table                 â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - Returns user_id from matching API key                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   - Updates last_used_at timestamp                       â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 2. Process Each Event:                                           â”‚  â”‚
â”‚  â”‚    for event_data in events:  # Batch processing                â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚      a. Idempotency Check:                                      â”‚  â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚         â”‚ existing = session.query(TraceEvent).filter(      â”‚  â”‚  â”‚
â”‚  â”‚         â”‚     TraceEvent.span_id == event_data.span_id,     â”‚  â”‚  â”‚
â”‚  â”‚         â”‚     TraceEvent.user_id == user_id                 â”‚  â”‚  â”‚
â”‚  â”‚         â”‚ ).first()                                         â”‚  â”‚  â”‚
â”‚  â”‚         â”‚                                                    â”‚  â”‚  â”‚
â”‚  â”‚         â”‚ if existing:                                       â”‚  â”‚  â”‚
â”‚  â”‚         â”‚     skipped_count += 1                            â”‚  â”‚  â”‚
â”‚  â”‚         â”‚     continue  # Skip duplicate                     â”‚  â”‚  â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚      b. Compute Cost (if missing):                              â”‚  â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚         â”‚ if event_data.cost_usd == 0.0:                    â”‚  â”‚  â”‚
â”‚  â”‚         â”‚     event_data.cost_usd = compute_cost(            â”‚  â”‚  â”‚
â”‚  â”‚         â”‚         provider=event_data.provider,              â”‚  â”‚  â”‚
â”‚  â”‚         â”‚         model=event_data.model,                    â”‚  â”‚  â”‚
â”‚  â”‚         â”‚         input_tokens=event_data.input_tokens,      â”‚  â”‚  â”‚
â”‚  â”‚         â”‚         output_tokens=event_data.output_tokens     â”‚  â”‚  â”‚
â”‚  â”‚         â”‚     )                                               â”‚  â”‚  â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚      c. Create Database Record:                                  â”‚  â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚         â”‚ event_dict = event_data.model_dump()               â”‚  â”‚  â”‚
â”‚  â”‚         â”‚ event_dict["user_id"] = user_id  # Inject user_id  â”‚  â”‚  â”‚
â”‚  â”‚         â”‚ event = TraceEvent(**event_dict)                   â”‚  â”‚  â”‚
â”‚  â”‚         â”‚ session.add(event)                                  â”‚  â”‚  â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 3. Commit to Database:                                          â”‚  â”‚
â”‚  â”‚    session.commit()  # SQLite or PostgreSQL                     â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 4. Return Response:                                              â”‚  â”‚
â”‚  â”‚    {                                                             â”‚  â”‚
â”‚  â”‚      "status": "success",                                       â”‚  â”‚
â”‚  â”‚      "created": 10,  # Number of events created                 â”‚  â”‚
â”‚  â”‚      "skipped": 2    # Number of duplicate events               â”‚  â”‚
â”‚  â”‚    }                                                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ Stored in SQLite/PostgreSQL
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DATABASE (SQLModel)                                         â”‚
â”‚                                                                         â”‚
â”‚  TraceEvent Table Structure:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ CREATE TABLE trace_events (                                      â”‚  â”‚
â”‚  â”‚     id TEXT PRIMARY KEY,                                         â”‚  â”‚
â”‚  â”‚     run_id TEXT INDEX,                                          â”‚  â”‚
â”‚  â”‚     span_id TEXT,                                                â”‚  â”‚
â”‚  â”‚     parent_span_id TEXT,                                         â”‚  â”‚
â”‚  â”‚     section TEXT INDEX,                                           â”‚  â”‚
â”‚  â”‚     section_path TEXT INDEX,                                     â”‚  â”‚
â”‚  â”‚     span_type TEXT,                                               â”‚  â”‚
â”‚  â”‚     provider TEXT,                                                â”‚  â”‚
â”‚  â”‚     endpoint TEXT,                                                 â”‚  â”‚
â”‚  â”‚     model TEXT,                                                    â”‚  â”‚
â”‚  â”‚     user_id UUID FOREIGN KEY,                                      â”‚  â”‚
â”‚  â”‚     customer_id TEXT INDEX,                                       â”‚  â”‚
â”‚  â”‚     input_tokens INTEGER,                                          â”‚  â”‚
â”‚  â”‚     output_tokens INTEGER,                                         â”‚  â”‚
â”‚  â”‚     cached_tokens INTEGER,                                          â”‚  â”‚
â”‚  â”‚     cost_usd REAL,                                                  â”‚  â”‚
â”‚  â”‚     latency_ms REAL,                                               â”‚  â”‚
â”‚  â”‚     status TEXT,                                                    â”‚  â”‚
â”‚  â”‚     is_streaming INTEGER,                                           â”‚  â”‚
â”‚  â”‚     stream_cancelled INTEGER,                                       â”‚  â”‚
â”‚  â”‚     created_at TIMESTAMP,                                           â”‚  â”‚
â”‚  â”‚     event_metadata JSON                                             â”‚  â”‚
â”‚  â”‚ )                                                                   â”‚  â”‚
â”‚  â”‚                                                                     â”‚  â”‚
â”‚  â”‚ Indexes:                                                            â”‚  â”‚
â”‚  â”‚   - idx_run_id (run_id)                                            â”‚  â”‚
â”‚  â”‚   - idx_section_path (section_path)                                â”‚  â”‚
â”‚  â”‚   - idx_user_id (user_id)                                          â”‚  â”‚
â”‚  â”‚   - idx_customer_id (customer_id)                                   â”‚  â”‚
â”‚  â”‚   - idx_user_created (user_id, created_at)                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ HTTP GET /runs, /insights, etc.
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FRONTEND (Next.js)                                          â”‚
â”‚                                                                         â”‚
â”‚  Dashboard Page Flow:                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Page Loads:                                                   â”‚  â”‚
â”‚  â”‚    useEffect(() => {                                             â”‚  â”‚
â”‚  â”‚        loadRuns()                                                 â”‚  â”‚
â”‚  â”‚        loadInsights()                                             â”‚  â”‚
â”‚  â”‚    }, [selectedCustomer])                                         â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 2. Fetch Runs:                                                     â”‚  â”‚
â”‚  â”‚    GET /runs/latest?days=7                                        â”‚  â”‚
â”‚  â”‚    â†’ Returns list of runs with aggregated stats                  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 3. Fetch Run Details:                                             â”‚  â”‚
â”‚  â”‚    For each run:                                                  â”‚  â”‚
â”‚  â”‚      GET /runs/{run_id}                                           â”‚  â”‚
â”‚  â”‚      â†’ Returns all events for that run                            â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 4. Filter by Customer (if selected):                              â”‚  â”‚
â”‚  â”‚    filteredEvents = allEvents.filter(                             â”‚  â”‚
â”‚  â”‚        e => e.customer_id === selectedCustomer                   â”‚  â”‚
â”‚  â”‚    )                                                               â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 5. Calculate Statistics:                                          â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ stats = {                                                â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     total_cost_24h: sum of filteredEvents.cost_usd       â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     total_calls_24h: filteredEvents.length               â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     avg_cost_per_call: total_cost / total_calls          â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     total_runs: unique run_ids                           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     cost_change: vs 7 days ago                           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ }                                                          â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 6. Aggregate by Provider/Agent:                                  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚    â”‚ byProvider = aggregateByProvider(filteredEvents)         â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Groups events by provider                             â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Sums cost, counts calls, averages latency            â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ byAgent = aggregateByAgent(filteredEvents)              â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Filters for section_path.startsWith("agent:")       â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Groups by agent name                                  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚   â†’ Sums cost, counts calls                                â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 7. Render UI:                                                    â”‚  â”‚
â”‚  â”‚    - KPI Cards (Total Cost, Calls, Runs, Change %)              â”‚  â”‚
â”‚  â”‚    - Provider Stats Table                                        â”‚  â”‚
â”‚  â”‚    - Agent Stats Table                                           â”‚  â”‚
â”‚  â”‚    - Recent Runs List                                            â”‚  â”‚
â”‚  â”‚    - Customer Filter Dropdown                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Granular Component Details

### 1. Context Management (context.py)

**ContextVars - Async-Safe State:**

```python
# ContextVar storage (one per async task/thread)
_run_id_var = ContextVar("run_id", default=None)
_customer_id_var = ContextVar("customer_id", default=None)
_section_stack_var = ContextVar("section_stack", default=None)
```

**How ContextVars Work:**
- Each async task/thread gets its own copy of the context
- Changes in one task don't affect another
- Perfect for async frameworks (FastAPI, async Django)

**Section Stack (Hierarchical Tracing):**

```python
with section("agent:researcher"):
    # section_stack = [
    #     {"label": "agent:researcher", "span_id": "uuid-1", "parent_span_id": None}
    # ]
    
    with section("tool:web_search"):
        # section_stack = [
        #     {"label": "agent:researcher", "span_id": "uuid-1", "parent_span_id": None},
        #     {"label": "tool:web_search", "span_id": "uuid-2", "parent_span_id": "uuid-1"}
        # ]
        
        # OpenAI call happens here
        response = client.embeddings.create(...)
        # Event gets:
        #   - section_path: "agent:researcher/tool:web_search"
        #   - span_id: "uuid-2"
        #   - parent_span_id: "uuid-1"
```

**Context Export/Import (for Workers):**

```python
# In main process:
context_data = context.export()
# Returns: {"run_id": "...", "customer_id": "...", "section_stack": [...]}

# In Celery worker:
context.import_context(context_data)
# Restores context in worker process
```

---

### 2. Streaming Response Handling

**Sync Streaming:**

```python
def _wrap_streaming_response(stream, ...):
    accumulated_usage = {"input_tokens": 0, "output_tokens": 0, "cached_tokens": 0}
    accumulated_content = ""
    chunks_received = 0
    
    try:
        for chunk in stream:
            chunks_received += 1
            
            # Extract usage from chunk (OpenAI sends in last chunk)
            if hasattr(chunk, "usage"):
                accumulated_usage["input_tokens"] = chunk.usage.prompt_tokens
                accumulated_usage["output_tokens"] = chunk.usage.completion_tokens
            
            # Accumulate content for estimation if cancelled
            if hasattr(chunk, "choices"):
                accumulated_content += chunk.choices[0].delta.content
            
            yield chunk  # Forward chunk to user
            
    except GeneratorExit:
        # Stream was cancelled
        # Estimate tokens if we don't have usage data
        if accumulated_usage["output_tokens"] == 0:
            accumulated_usage["output_tokens"] = estimate_tokens(accumulated_content, model)
        
    finally:
        # Emit event after stream completes
        if chunks_received > 0:
            track_openai_call(..., response=mock_response_with_usage)
```

**Async Streaming:**

```python
async def async_stream_wrapper():
    # Same logic but async
    async for chunk in response:
        # Extract usage, accumulate content
        yield chunk
    # Track in finally block
```

---

### 3. Cost Calculation (pricing.py)

**Pricing Registry Structure:**

```python
PRICING_REGISTRY = {
    "openai:gpt-4o": {
        "input": 0.000005,   # per 1K tokens
        "output": 0.000015
    },
    "openai:gpt-4o-mini": {
        "input": 0.00000015,
        "output": 0.0000006
    },
    # ... hundreds of models
}
```

**Cost Calculation Logic:**

```python
def compute_cost(provider, model, input_tokens, output_tokens, cached_tokens=0):
    # 1. Build lookup key
    key = f"{provider}:{model}"
    
    # 2. Look up pricing
    pricing = PRICING_REGISTRY.get(key)
    if not pricing:
        return 0.0  # Unknown model = $0
    
    # 3. Calculate costs
    input_cost = (input_tokens / 1000) * pricing["input"]
    output_cost = (output_tokens / 1000) * pricing["output"]
    
    # 4. Apply cached token discount (10% of input cost)
    cached_cost = (cached_tokens / 1000) * pricing["input"] * 0.1
    
    # 5. Total
    total = input_cost + output_cost - cached_cost
    return total
```

---

### 4. Database Schema (models.py)

**TraceEvent Table:**

```sql
CREATE TABLE trace_events (
    -- Primary key
    id TEXT PRIMARY KEY,  -- UUID4
    
    -- Grouping
    run_id TEXT INDEX,    -- Groups events into logical runs
    span_id TEXT,         -- Unique span identifier
    parent_span_id TEXT,   -- Parent span (for hierarchy)
    
    -- Categorization
    section TEXT INDEX,           -- Last segment: "step:analyze"
    section_path TEXT INDEX,      -- Full path: "agent:researcher/tool:web_search/step:analyze"
    span_type TEXT,               -- "llm", "vector_db", "api", "other"
    provider TEXT,                -- "openai", "pinecone", etc.
    endpoint TEXT,                -- "chat.completions.create", "query", etc.
    model TEXT,                   -- "gpt-4o", "text-embedding-3-small", etc.
    
    -- Multi-tenancy
    user_id UUID FOREIGN KEY,     -- Owner (from API key)
    customer_id TEXT INDEX,       -- End-user (user's customers)
    
    -- Metrics
    input_tokens INTEGER,
    output_tokens INTEGER,
    cached_tokens INTEGER,
    cost_usd REAL,
    latency_ms REAL,
    
    -- Status
    status TEXT,                  -- "ok", "error", "cancelled", "rate_limited"
    is_streaming INTEGER,
    stream_cancelled INTEGER,
    
    -- Timestamps
    created_at TIMESTAMP,
    
    -- Metadata
    event_metadata JSON            -- Arbitrary data (retry info, etc.)
)
```

**Indexes for Performance:**

```sql
CREATE INDEX idx_run_id ON trace_events(run_id);
CREATE INDEX idx_section_path ON trace_events(section_path);
CREATE INDEX idx_user_id ON trace_events(user_id);
CREATE INDEX idx_customer_id ON trace_events(customer_id);
CREATE INDEX idx_user_created ON trace_events(user_id, created_at);
```

---

### 5. Frontend Data Flow

**Dashboard Page (page.tsx):**

```typescript
// 1. Fetch runs
const runs = await fetchRuns(days=7)
// GET /runs/latest?days=7
// Returns: [{run_id, total_cost, total_tokens, events_count, ...}]

// 2. Fetch details for each run
for (const run of runs) {
    const detail = await fetchRunDetail(run.run_id)
    // GET /runs/{run_id}
    // Returns: {run_id, events: [{...event data...}]}
}

// 3. Collect all events
const allEvents = runs.flatMap(run => run.detail.events)

// 4. Filter by customer (if selected)
const filteredEvents = selectedCustomer
    ? allEvents.filter(e => e.customer_id === selectedCustomer)
    : allEvents

// 5. Calculate statistics
const stats = {
    total_cost_24h: filteredEvents.reduce((sum, e) => sum + e.cost_usd, 0),
    total_calls_24h: filteredEvents.length,
    avg_cost_per_call: total_cost / total_calls,
    total_runs: new Set(filteredEvents.map(e => e.run_id)).size,
    cost_change: calculateChange(filteredEvents, weekAgoEvents)
}

// 6. Aggregate by provider
const byProvider = aggregateByProvider(filteredEvents)
// Groups by provider, sums cost, counts calls

// 7. Aggregate by agent
const byAgent = aggregateByAgent(filteredEvents)
// Filters for section_path.startsWith("agent:")
// Groups by agent name

// 8. Render UI
<KPICard value={stats.total_cost_24h} />
<ProviderStatsTable data={byProvider} />
<AgentStatsTable data={byAgent} />
```

---

### 6. Hierarchical Trace Building

**Tree Construction (HierarchicalTrace.tsx):**

```typescript
function buildTraceTree(events: TraceEvent[]): TreeNode[] {
    // 1. Build map of span_id -> event
    const eventMap = new Map<string, TraceEvent>()
    events.forEach(e => eventMap.set(e.span_id, e))
    
    // 2. Build parent-child relationships
    const childrenMap = new Map<string, TraceEvent[]>()
    events.forEach(e => {
        if (e.parent_span_id) {
            if (!childrenMap.has(e.parent_span_id)) {
                childrenMap.set(e.parent_span_id, [])
            }
            childrenMap.get(e.parent_span_id)!.push(e)
        }
    })
    
    // 3. Find root nodes (no parent_span_id)
    const roots = events.filter(e => !e.parent_span_id)
    
    // 4. Recursively build tree
    function buildNode(event: TraceEvent): TreeNode {
        const children = childrenMap.get(event.span_id) || []
        return {
            event,
            children: children.map(buildNode),
            cost: event.cost_usd + sum(children.map(c => c.cost)),
            latency: event.latency_ms + sum(children.map(c => c.latency))
        }
    }
    
    return roots.map(buildNode)
}
```

**Tree Rendering:**

```typescript
function TreeNodeComponent({node, depth, isLast, parentPrefix}) {
    // Tree lines: "â”œâ”€", "â””â”€", "â”‚ "
    const lineChar = isLast ? "â””â”€" : "â”œâ”€"
    const continueChar = isLast ? "  " : "â”‚ "
    
    return (
        <div>
            <span>{parentPrefix}{lineChar}</span>
            <Badge>{node.event.section_path}</Badge>
            <span>${node.cost.toFixed(6)}</span>
            <span>{node.latency.toFixed(0)}ms</span>
            
            {node.children.map((child, idx) => (
                <TreeNodeComponent
                    node={child}
                    depth={depth + 1}
                    isLast={idx === node.children.length - 1}
                    parentPrefix={parentPrefix + continueChar}
                />
            ))}
        </div>
    )
}
```

---

### 7. Fail-Open Safety Pattern

**Every Wrapper Follows This Pattern:**

```python
def sync_wrapper(*args, **kwargs):
    try:
        # CRITICAL PATH: Always call original method
        response = original_method(*args, **kwargs)
        
        # TRACKING: Wrap in try/except (fail-open)
        try:
            track_openai_call(...)
        except Exception as e:
            logger.debug(f"Tracking failed: {e}")
            # Don't break - just log and continue
        
        return response  # Always return original response
        
    except Exception as e:
        # ERROR TRACKING: Wrap in try/except (fail-open)
        try:
            track_openai_call(..., error=e)
        except Exception:
            pass  # Don't break on tracking failure
        
        raise  # Always re-raise original exception
```

**Why This Works:**
- Original method is always called (critical path)
- Tracking failures don't break user code
- Errors are tracked but don't interfere
- User's code behaves exactly as before

---

### 8. Thread Safety

**Buffer (Thread-Safe Queue):**

```python
# queue.Queue is thread-safe
_event_queue = queue.Queue(maxsize=10000)

# Multiple threads can add simultaneously
def add_event(event):
    _event_queue.put_nowait(event)  # Thread-safe operation

# Flush timer runs in separate thread
def start_flush_timer():
    _flush_timer = threading.Timer(interval, _flush_and_reschedule)
    _flush_timer.daemon = True  # Doesn't block shutdown
    _flush_timer.start()
```

**Context (Async-Safe with ContextVars):**

```python
# ContextVars are async-safe
_run_id_var = ContextVar("run_id")

# Each async task gets its own context
async def task1():
    context.set_run_id("run-1")  # Only affects task1

async def task2():
    context.set_run_id("run-2")  # Only affects task2

# Both can run concurrently without interference
```

---

### 9. Data Flow Example

**Complete Flow for One API Call:**

```
1. User Code:
   with section("agent:researcher"):
       response = client.chat.completions.create(...)

2. SDK Intercepts:
   â†’ sync_wrapper() is called instead of original method
   â†’ Extracts: model="gpt-4o", is_streaming=False
   â†’ Records: start_time = 1234567890.123

3. Calls Original:
   â†’ original_method(*args, **kwargs)
   â†’ Returns: OpenAI response object

4. Extracts Usage:
   â†’ input_tokens = response.usage.prompt_tokens (100)
   â†’ output_tokens = response.usage.completion_tokens (50)
   â†’ cached_tokens = response.usage.prompt_tokens_details.cached_tokens (20)

5. Calculates Cost:
   â†’ Looks up "openai:gpt-4o" in PRICING_REGISTRY
   â†’ input_cost = (100/1000) * 0.000005 = $0.0000005
   â†’ output_cost = (50/1000) * 0.000015 = $0.00000075
   â†’ cached_cost = (20/1000) * 0.000005 * 0.1 = $0.00000001
   â†’ total = $0.00000124

6. Gets Context:
   â†’ run_id = context.get_run_id() â†’ "abc-123"
   â†’ section_path = context.get_section_path() â†’ "agent:researcher"
   â†’ span_id = context.get_current_span_id() â†’ "span-456"
   â†’ parent_span_id = context.get_parent_span_id() â†’ None
   â†’ customer_id = context.get_customer_id() â†’ "customer_123"

7. Calculates Latency:
   â†’ latency_ms = (time.time() - start_time) * 1000 = 1250.5

8. Creates Event:
   â†’ event = {
         "id": "event-789",
         "run_id": "abc-123",
         "span_id": "span-456",
         "parent_span_id": None,
         "section": "agent:researcher",
         "section_path": "agent:researcher",
         "provider": "openai",
         "endpoint": "chat.completions.create",
         "model": "gpt-4o",
         "customer_id": "customer_123",
         "input_tokens": 100,
         "output_tokens": 50,
         "cached_tokens": 20,
         "cost_usd": 0.00000124,
         "latency_ms": 1250.5,
         "status": "ok",
         ...
       }

9. Adds to Buffer:
   â†’ buffer.add_event(event)
   â†’ _event_queue.put_nowait(event)  # Thread-safe

10. Background Timer (500ms later):
    â†’ flush_events() is called
    â†’ events = get_and_clear_buffer()  # Gets all buffered events
    â†’ HTTP POST to http://localhost:8000/events
    â†’ Body: [event1, event2, event3, ...]  # Batch

11. Collector Receives:
    â†’ POST /events with batch of events
    â†’ Authenticates via API key â†’ gets user_id
    â†’ For each event:
       - Checks idempotency (span_id + user_id)
       - Computes cost if missing
       - Stores in database
    â†’ Returns: {"status": "success", "created": 10}

12. Frontend Queries:
    â†’ GET /runs/latest?days=7
    â†’ Returns runs with aggregated stats
    â†’ GET /runs/{run_id}
    â†’ Returns all events for that run
    â†’ Builds tree from span_id/parent_span_id
    â†’ Renders hierarchical trace with costs
```

---

## ğŸ¯ Key Design Decisions

### Why ContextVars?
- Async-safe: Each async task gets its own context
- No thread-local storage needed
- Works with FastAPI, async Django, etc.

### Why Bounded Queue?
- Prevents memory bloat if collector is down
- Drop-oldest policy: lose old data, keep new
- Thread-safe: multiple threads can add simultaneously

### Why Batch Sending?
- Reduces HTTP overhead (1 request vs 100)
- More efficient for high-volume apps
- Configurable flush interval (default 500ms)

### Why Fail-Open?
- Never breaks user's application
- Tracking failures are silent
- Better to lose telemetry than crash user's code

### Why Idempotency?
- Prevents duplicate events on retries
- Safe to call multiple times
- Based on span_id (unique per call)

---

## ğŸ”„ Complete Request Flow

**Example: User makes a chat completion call**

```
Time 0ms:   User calls client.chat.completions.create(...)
Time 0ms:   SDK wrapper intercepts
Time 0ms:   Records start_time = 1234567890.123
Time 0ms:   Calls original OpenAI method
Time 1250ms: OpenAI returns response
Time 1250ms: SDK extracts usage (100/50 tokens)
Time 1250ms: SDK calculates cost ($0.00000124)
Time 1250ms: SDK gets context (run_id, section_path, etc.)
Time 1250ms: SDK creates event object
Time 1250ms: SDK adds event to buffer (queue)
Time 1250ms: SDK returns response to user
Time 1750ms: Background timer fires (500ms later)
Time 1750ms: flush_events() called
Time 1750ms: Drains buffer (gets all events)
Time 1750ms: HTTP POST to /events (batch)
Time 1760ms: Collector receives batch
Time 1760ms: Collector authenticates (API key â†’ user_id)
Time 1760ms: Collector checks idempotency (span_id)
Time 1760ms: Collector stores in database
Time 1761ms: Collector returns success
Time 2000ms: User refreshes dashboard
Time 2000ms: Frontend GET /runs/latest
Time 2001ms: Backend queries database
Time 2001ms: Backend aggregates by run_id
Time 2002ms: Backend returns runs list
Time 2002ms: Frontend GET /runs/{run_id} for each run
Time 2003ms: Backend returns events for each run
Time 2003ms: Frontend builds tree from span_id/parent_span_id
Time 2003ms: Frontend renders hierarchical trace
```

---

## ğŸ›¡ï¸ Safety Mechanisms

1. **Version Guards**: Warns on unknown SDK versions
2. **Conflict Detection**: Detects other patching libraries
3. **Fail-Open**: Never breaks user code
4. **Idempotency**: Safe to retry
5. **Bounded Queue**: Prevents memory bloat
6. **Exponential Backoff**: Reduces load on collector
7. **Signal Handling**: Flushes on shutdown
8. **Thread Safety**: Queue is thread-safe
9. **Async Safety**: ContextVars are async-safe

---

This is how the system works at a granular level. Each component is designed to be safe, efficient, and production-ready.

